{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "7.RNN.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/text/text_generation.ipynb",
     "timestamp": 1565900142296
    }
   ],
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:tpu_hw_notebook",
    "kind": "private"
   }
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## REDES NEURONALES RECURRENTES<a class=\"tocSkip\">\n",
    "## EL460 ELECTIVA III - Deep Learning <a class=\"tocSkip\">\n",
    "### Ingenieria Electrónica <a class=\"tocSkip\">\n",
    "### Universidad Popular del Cesar <a class=\"tocSkip\">\n",
    "### Prof.: Jose Ramón Iglesias Gamarra - [https://github.com/joseramoniglesias/](https://github.com/joseramoniglesias/) <a class=\"tocSkip\">\n",
    "**joseiglesias@unicesar.edu.co**# Redes Neuronales Recurrentes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Redes Neuronales Recurrentes\n",
    "### Deep Learning, Introducción práctica con Keras - Segunda parte"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Importar TensorFlow 2.0  y otras librerias"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zWrJnG1jZd00",
    "colab_type": "code",
    "outputId": "909498c7-b016-4c76-dcb4-dd1db0211cc4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555492,
     "user_tz": -120,
     "elapsed": 40472,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    }
   },
   "source": [
    "!pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.0.0-alpha0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
      "\u001B[K     |████████████████████████████████| 332.1MB 83kB/s \n",
      "\u001B[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
      "\u001B[K     |████████████████████████████████| 419kB 51.7MB/s \n",
      "\u001B[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.7)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.6)\n",
      "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
      "\u001B[K     |████████████████████████████████| 3.0MB 46.9MB/s \n",
      "\u001B[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.5)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
      "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
      "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n",
      "2.0.0-alpha0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### Descarga del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "pD_55cOxLkAb",
    "outputId": "240a44d7-e047-4438-8b4d-668b7ba5cb04",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555494,
     "user_tz": -120,
     "elapsed": 40466,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    }
   },
   "source": [
    "path_to_fileDL = tf.keras.utils.get_file('DL-Introduccion-practica-con-Keras-1aParte.txt', 'https://raw.githubusercontent.com/joseramoniglesias/EL469_DeepLearning/main/Cap02_PerceivingUnderstanding_VisualWorld/Assignment/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt)  \n",
    "\n",
    "#path_to_fileDL = tf.keras.utils.get_file('Shakespear.txt', 'https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt')\n",
    "\n",
    "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
    "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
    "print (vocab)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt\n",
      "204800/203286 [==============================] - 0s 0us/step\n",
      "Longitud del texto:        203251 carácteres\n",
      "El texto está compuesto de estos 92 carácteres:\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "IalZLbvOzf-F",
    "outputId": "a2fe0ad2-6286-432e-b1fe-1dad86e5e94b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555495,
     "user_tz": -120,
     "elapsed": 40462,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "for char,_ in zip(char2idx, range(len(vocab))):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "  '\\n':   0,\n",
      "  '\\r':   1,\n",
      "  ' ' :   2,\n",
      "  '!' :   3,\n",
      "  '\"' :   4,\n",
      "  '#' :   5,\n",
      "  '%' :   6,\n",
      "  \"'\" :   7,\n",
      "  '(' :   8,\n",
      "  ')' :   9,\n",
      "  '*' :  10,\n",
      "  '+' :  11,\n",
      "  ',' :  12,\n",
      "  '-' :  13,\n",
      "  '.' :  14,\n",
      "  '/' :  15,\n",
      "  '0' :  16,\n",
      "  '1' :  17,\n",
      "  '2' :  18,\n",
      "  '3' :  19,\n",
      "  '4' :  20,\n",
      "  '5' :  21,\n",
      "  '6' :  22,\n",
      "  '7' :  23,\n",
      "  '8' :  24,\n",
      "  '9' :  25,\n",
      "  ':' :  26,\n",
      "  ';' :  27,\n",
      "  '<' :  28,\n",
      "  '=' :  29,\n",
      "  '>' :  30,\n",
      "  '?' :  31,\n",
      "  '@' :  32,\n",
      "  'A' :  33,\n",
      "  'B' :  34,\n",
      "  'C' :  35,\n",
      "  'D' :  36,\n",
      "  'E' :  37,\n",
      "  'F' :  38,\n",
      "  'G' :  39,\n",
      "  'H' :  40,\n",
      "  'I' :  41,\n",
      "  'J' :  42,\n",
      "  'K' :  43,\n",
      "  'L' :  44,\n",
      "  'M' :  45,\n",
      "  'N' :  46,\n",
      "  'O' :  47,\n",
      "  'P' :  48,\n",
      "  'Q' :  49,\n",
      "  'R' :  50,\n",
      "  'S' :  51,\n",
      "  'T' :  52,\n",
      "  'U' :  53,\n",
      "  'V' :  54,\n",
      "  'W' :  55,\n",
      "  'X' :  56,\n",
      "  'Y' :  57,\n",
      "  '[' :  58,\n",
      "  ']' :  59,\n",
      "  '_' :  60,\n",
      "  'a' :  61,\n",
      "  'b' :  62,\n",
      "  'c' :  63,\n",
      "  'd' :  64,\n",
      "  'e' :  65,\n",
      "  'f' :  66,\n",
      "  'g' :  67,\n",
      "  'h' :  68,\n",
      "  'i' :  69,\n",
      "  'j' :  70,\n",
      "  'k' :  71,\n",
      "  'l' :  72,\n",
      "  'm' :  73,\n",
      "  'n' :  74,\n",
      "  'o' :  75,\n",
      "  'p' :  76,\n",
      "  'q' :  77,\n",
      "  'r' :  78,\n",
      "  's' :  79,\n",
      "  't' :  80,\n",
      "  'u' :  81,\n",
      "  'v' :  82,\n",
      "  'w' :  83,\n",
      "  'x' :  84,\n",
      "  'y' :  85,\n",
      "  'z' :  86,\n",
      "  '\\xad':  87,\n",
      "  'ÿ' :  88,\n",
      "  'Š' :  89,\n",
      "  '‡' :  90,\n",
      "  '…' :  91,\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ML-DuUyi_aHy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "l1VKcQHcymwb",
    "outputId": "ae9f8163-e3ba-4e8d-d5e8-9963ee511479",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555902,
     "user_tz": -120,
     "elapsed": 40858,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    }
   },
   "source": [
    "print ('texto: {}'.format(repr(text[:50])))\n",
    "print ('{}'.format(repr(text_as_int[:50])))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "texto: 'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fun'\n",
      "array([48, 78, 75, 72, 75, 67, 75,  1,  0, 37, 74,  2, 17, 25, 21, 19, 12,\n",
      "        2, 41, 79, 61, 61, 63,  2, 33, 79, 69, 73, 75, 82,  2, 76, 81, 62,\n",
      "       72, 69, 63, 75,  2, 51, 65, 67, 81, 74, 64, 61,  2, 38, 81, 74])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Preparar los datos para entrenar la RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "0UHJDA39zf-O",
    "colab": {}
   },
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "seq_length = 100\n",
    " \n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "l4hkDU3i7ozi",
    "outputId": "359c3657-54a9-4bee-c284-d2ce5e74b3a3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555904,
     "user_tz": -120,
     "elapsed": 40849,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    }
   },
   "source": [
    "for item in sequences.take(10):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n",
      "'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n",
      "' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n",
      "'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n",
      "'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n",
      "'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n",
      "' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n",
      "' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n",
      "'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n",
      "'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "9NGu-FkO_kYU",
    "colab": {}
   },
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "GNbw-iR0ymwj",
    "outputId": "62cb263e-b815-4e6f-e5ee-4de68ed4e1b2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555905,
     "user_tz": -120,
     "elapsed": 40839,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    }
   },
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n",
      "Target data: 'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "0eBu9WZG84i0",
    "outputId": "e1ba7b19-33a8-4df0-c7a9-7914bce17b02",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555906,
     "user_tz": -120,
     "elapsed": 40833,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "print (dataset)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "p2pGotuNzf-S",
    "outputId": "0a08cc7c-6684-4a88-a592-f3a527284642",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555907,
     "user_tz": -120,
     "elapsed": 40826,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print (dataset)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "### Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "zHT8cLh7EAsg",
    "colab": {}
   },
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "MtCrdfzEI2N0",
    "colab": {}
   },
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "wwsrpOik5zhv",
    "outputId": "98e212ec-f9c6-4ba0-92d6-861fd9178d19",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818555909,
     "user_tz": -120,
     "elapsed": 40814,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fdbc0acd898>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PpHGXDMcZ0Zt",
    "colab_type": "code",
    "outputId": "8d448fdd-ffad-417d-e492-ebe27d8ac17e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818557122,
     "user_tz": -120,
     "elapsed": 42021,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23552     \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 92)            94300     \n",
      "=================================================================\n",
      "Total params: 5,364,828\n",
      "Trainable params: 5,364,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "C-_70kKAPrPU",
    "outputId": "dfab0fc7-3326-4491-8318-07d1fbdb473b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818557123,
     "user_tz": -120,
     "elapsed": 42017,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    }
   },
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
    "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")\n"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Input: (64, 100) # (batch_size, sequence_length)\n",
      "Target: (64, 100) # (batch_size, sequence_length)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "udE_6eTldMhB",
    "colab_type": "code",
    "outputId": "c59f76ef-b449-4143-e1d0-87c442727fd2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818562660,
     "user_tz": -120,
     "elapsed": 47547,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):  \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Prediction:  (64, 100, 92) # (batch_size, sequence_length, vocab_size)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "4V4MfFg0RQJg",
    "colab": {}
   },
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "YqFMUQc_UFgM",
    "outputId": "9ed0d2be-20c8-4089-de47-26c3f97f5915",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818562662,
     "user_tz": -120,
     "elapsed": 47539,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    }
   },
   "source": [
    "sampled_indices_characters"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1, 89, 85, 20,  6, 73, 54, 40,  7, 57,  3, 67, 81, 47, 19, 14, 81,\n",
       "       35, 78, 37, 90, 34, 50, 46, 35,  7, 73,  4, 59, 75,  6, 48, 28, 82,\n",
       "       14, 78,  2, 68, 72, 23, 87, 66, 70, 19, 78, 38, 48, 65,  6, 36, 87,\n",
       "       66, 69, 76, 57,  2, 89, 54, 26, 57, 37, 12,  1, 47,  0, 51, 52, 18,\n",
       "       48, 87,  9, 48, 55, 67, 79, 22, 54, 53, 49,  2, 17, 76, 40, 32, 60,\n",
       "       59, 22, 32, 82, 47, 35, 59, 66, 86,  8, 39, 60, 61, 68, 40])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "4HrXTACTdzY-",
    "colab": {}
   },
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "DDl1_Een6rL0",
    "colab": {}
   },
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieSJdchZggUj"
   },
   "source": [
    "Configurar el *checkpoints*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "W6fWTriUZP-n",
    "colab": {}
   },
   "source": [
    " # directorio\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# nombre fichero\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "*Training*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "UK-hmKjYVoll",
    "outputId": "b6b61770-7df4-4fb4-9ef4-aa8162808ae7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818694957,
     "user_tz": -120,
     "elapsed": 179814,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "EPOCHS=50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 3.2626\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 2.7938\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 2.4345\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 2.2087\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 2.0815\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 1.9603\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 1.8362\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 1.7192\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.6094\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 1.5072\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 3s 87ms/step - loss: 1.4165\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.3356\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.2693\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 3s 89ms/step - loss: 1.2046\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.1445\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.0885\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 1.0371\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.9919\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.9482\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.9019\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.8546\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.8130\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.7694\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.7322\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.6897\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.6468\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.6114\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.5719\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.5349\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.4936\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.4589\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.4301\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.4010\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.3739\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.3510\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.3335\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.3160\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.2952\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.2707\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.2473\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.2284\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 0.2078\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.1907\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.1738\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.1572\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.1446\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.1352\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.1224\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 0.1096\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.0976\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "### Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "zk2WJ2-XjkGz",
    "outputId": "65cc78fc-d194-44d3-acb2-1d8cf2c8d2d2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818694958,
     "user_tz": -120,
     "elapsed": 179807,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_50'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "LycQ-ot_jjyu",
    "outputId": "575cb534-a089-4eaf-f894-ca056b623177",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818694959,
     "user_tz": -120,
     "elapsed": 179802,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fdb4a6a0be0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd",
    "colab": {}
   },
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "  num_generate = 500\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "\n",
    "\n",
    "  temperature = 0.5\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "ktovv0RFhrkn",
    "outputId": "e462b01b-0462-459c-cd75-dd57e33509f8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818697309,
     "user_tz": -120,
     "elapsed": 182141,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    }
   },
   "source": [
    "print(generate_text(model, start_string=u\"Alcohol \"))"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Alcohol \n",
      "\r\n",
      "\n",
      "EBUNK9‡+[I**JJJxJK‡@'D]+k'J[‡!9‡DBX*X*WOIB­xRM‡]#WJ['IW\"@‡Wx@I%WGNYI%‡#xY[‡[%B[DIK‡]AQBJ/DB!W\"YYR‡?'IWQ%*YJII­H+B3Dx‡[A‡NQY*­5JQ+XIJwJWWJ\"N7D]YBCR‡YI‡%NHDK\n",
      "U@[x3I­<L!wJ'N9INzw@HB\"9J%>L…#JQJB#R<[L\n",
      "G%IhBD6JK'#]UHIVIY[BTJ<HPN]Y!'ÿ[!‡%*‡]RWJ%Y[D[R%H!JYUIH*I[[4kWQ'B]‡;'Y*[D9%‡WJ<[J*OGNB9\n",
      "JBNwJR'WJBKI#T9Jw?JYI3#[TQ@UJ*UGIQ!@V\"\"V9‡6\"JBG'3K'Yw‡TJ%IAzIQJ+''‡]DA9JJBHJ[F‡FxB\"<I3H9AhW\n",
      "x[JJHY‡BIJB#W<J9]‡2‡QIX\"JJ9GBQx;I‡xH]UD[GJJJ>\"j%x[zHH<JD[w\"*HH+I9Y[DÿD[INBR[DUGY+J#DwH!O[‡\"YX'KWJK\"'IY‡IHJJJ;9>D4‡YV9JKW\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PsNst9-GeiZo",
    "colab_type": "code",
    "outputId": "27d0c31a-2c56-4e18-f07c-6beed97ed8dd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818699459,
     "user_tz": -120,
     "elapsed": 184282,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "print(generate_text(model, start_string=u\"modelo\"))"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "modelo se usa para implementar modelos de redes muy grandes.  Para nuestro ejemplo simple, vemos que indica que se requiere mucha expericencambiendo su funcionamos el proceso de aprendizaje de una red neuronal. Ademas veremos algunos de los parametros W y b de tal manera que se minimice la funcion de loss que usaremos para evaluar el grado de error es un espacio de dos cientificos y cientificas de datos y que puedan solurio en la comunidad de programadores ya que permite ample mescampo. Ahora, es el t\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NFOd58ksem1a",
    "colab_type": "code",
    "outputId": "e6cdf1a2-e3b9-4f06-a022-96e2da3eea87",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1568818701619,
     "user_tz": -120,
     "elapsed": 186436,
     "user": {
      "displayName": "Jordi Torres",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDkD6udBQxc1Cx-zMrYPf0xjtQYxGjQEpB40wVHTg=s64",
      "userId": "14559872433417615139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "print(generate_text(model, start_string=u\"activacion\"))"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "activacion si la primera visto y es usaramos una de las predicciones por computador ya se conocian en 1989; tambien los algoritmos fundamentales de Deep Learning puede hacerlo a traves de la como de la UPC model prodecir esta siguiente paralelas Deep Learning ello tenemos otra metrica llamada Sensitivity (o recall) que nos indica como de bien el modelo evita el BSC para referirse a las diferentes actualizaciones de su supercomputador Marenostrum que tanta la provecho de las nuevas se pasan en glabal de da\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
