{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lab4_parte1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Laboratorio en clases<a class=\"tocSkip\">\n",
    "## EL460 ELECTIVA III - Deep Learning <a class=\"tocSkip\">\n",
    "### Ingenieria Electrónica <a class=\"tocSkip\">\n",
    "### Universidad Popular del Cesar <a class=\"tocSkip\">\n",
    "### Prof.: Jose Ramón Iglesias Gamarra - [https://github.com/joseramoniglesias/](https://github.com/joseramoniglesias/) <a class=\"tocSkip\">\n",
    "**joseiglesias@unicesar.edu.co**# "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zZt2JG85odtj",
    "ExecuteTime": {
     "end_time": "2023-10-20T11:33:35.992410900Z",
     "start_time": "2023-10-20T11:33:17.005824700Z"
    }
   },
   "source": [
    "#configuración del laboratorio\n",
    "# Ejecuta esta celda!\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#for local \n",
    "#import sys ; sys.path.append('../commons/utils/')\n",
    "!wget https://raw.githubusercontent.com/joseramoniglesias/EL469_DeepLearning/main/Cap02_PerceivingUnderstanding_VisualWorld/laboratorios/general.py -O general.py --no-cache\n",
    "from general import configure_lab4\n",
    "configure_lab4()\n",
    "from lab4 import *\n",
    "GRADER = part_1()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab configuration started\n",
      "installing libraries\n",
      "downloading files\n",
      "lab configured\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_ClassNamePrefixFeaturesOutMixin' from 'sklearn.base' (C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgeneral\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m configure_lab4\n\u001B[0;32m      9\u001B[0m configure_lab4()\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlab4\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     11\u001B[0m GRADER \u001B[38;5;241m=\u001B[39m part_1()\n",
      "File \u001B[1;32mC:\\Clases_UPC_2023_2\\EL469-ElectivaProcesamientoSeñales_3\\Clases_2023_2\\LaboratoriosenClase\\lab4\\lab4.py:15\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mEste archivo es generado automaticamente.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m###### NO MODIFICAR #########\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimports\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mneural_network\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLPRegressor\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ShuffleSplit\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_absolute_error, accuracy_score, mean_absolute_percentage_error,classification_report\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mThe :mod:`sklearn.neural_network` module includes models based on neural\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mnetworks.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# License: BSD 3 clause\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_rbm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BernoulliRBM\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_multilayer_perceptron\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLPClassifier\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_multilayer_perceptron\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLPRegressor\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_rbm.py:18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseEstimator\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TransformerMixin\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _ClassNamePrefixFeaturesOutMixin\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_random_state\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_even_slices\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name '_ClassNamePrefixFeaturesOutMixin' from 'sklearn.base' (C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEFZ1bNsodtm"
   },
   "source": [
    "# Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIyPCtR3odtm"
   },
   "source": [
    "Este ejercicio tiene como objetivo implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de regresión. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAVPFqINodtn"
   },
   "source": [
    "Para este ejercicio usaremos la base de datos sobre calidad del aire, que ha sido usada en laboratorios previos, pero en este caso trataremos de predecir dos variables en lugar de una, es decir, abordaremos **un problema de múltiples salidas**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S1ILV7RModtn"
   },
   "source": [
    "#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n",
    "db = np.loadtxt('AirQuality.data',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "#Esta es la base de datos AirQuality del UCI Machine Learning Repository. En la siguiente URL se encuentra toda\n",
    "#la descripción de la base de datos y la contextualización del problema.\n",
    "#https://archive.ics.uci.edu/ml/datasets/Air+Quality#\n",
    "\n",
    "x = db[:,0:11]\n",
    "y = db[:,11:13]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKlFuQyRodtp"
   },
   "source": [
    "Para calcular los errores, vamos a explorar y usar el [modulo de metricas den sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "Podemos observar que el modulo tiene metricas para regresión y clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFIUq69Modtp"
   },
   "source": [
    "### Ejercicio 1 - Experimentar con MLP para regresión\n",
    "\n",
    "Para porder implementar nuestra función, lo primero que debemos entender la estrucutra de la red. \n",
    "\n",
    "Como mencionamos, vamos a solucionar un problema de multiples salidas. Estas salidas con valores continuos. Por lo tanto debemos garantizar que la capa de salida de nuestra red tenga la capacidad de modelar este tipo de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "xjF6liTmodtp"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown ¿De acuerdo al problema planteado, que función de activación debe usar el MLP para un problema de regresión?\n",
    "respuesta_1 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G_bSsYcodtr"
   },
   "source": [
    "Una caracteristica de los modelos de sklearn, es que ciertos tipos de atributos, solo pueden ser accedidos cuanto se entrena el modelo. Vamos a realizar un pequeña función para comprobar cual es la capa de activación de los modelos MLP para regresión de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M0Rd2sBnodts"
   },
   "source": [
    "# ejercicio de código\n",
    "def output_activation():\n",
    "    \"\"\"funcion que entrena un modelo\n",
    "    con data aleatoria para confirmar la funcion\n",
    "    de activacion de la ultima capa\n",
    "    \"\"\"\n",
    "    mlp = MLPRegressor()\n",
    "    # fit with some random data\n",
    "    xrandom = np.random.rand(10,2)\n",
    "    yrandom = np.zeros(10)\n",
    "    # llamar el metodo adecuado para entrenar\n",
    "    # el mlp con los x y 'y' random\n",
    "    mlp.fit(, )\n",
    "    # retornar el atributo de mlp adecuado\n",
    "    return (mlp.)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mzJDEC1Bodtt"
   },
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio1\", output_activation)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p0ybj-1vodtv"
   },
   "source": [
    "print(\"la función de activación para un problema de regresion es:\", output_activation())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udcddNBiodtz"
   },
   "source": [
    "Una vez comprobado que sklearn usa la función de activación correcta, vamos crear la función para realizar los experimentos.\n",
    "\n",
    "Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.\n",
    "1. Como función de activación en las capas ocultas use la función 'tanh'. \n",
    "2. Ajuste el número máximo de épocas a 300.\n",
    "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa\n",
    "5. debemos seleccionar la función adecuada del [modulo de sklearn para calcular el Error Porcentual Absoluto Medio (MAPE en sigla en ingles)](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta que parametros usar.\n",
    "6. Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro `activation`, debe ser llamado: `MLPRegressor(activation=...)`\n",
    "7. Explorar que hace la siguiente linea de codigo `tuple(2*[100])`\n",
    "\n",
    "**NOTA**: cuando observe el el parametro `random_state=1` por favor conservarlo, ya que esto hace que los resultados sean similares a lo largo de las ejecucciones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y-SdZ9H_odt0"
   },
   "source": [
    "# ejercicio de código\n",
    "\n",
    "def experimetar_mlp(num_hidden_layers, num_neurons, X,Y):\n",
    "    \"\"\" función para realizar experimentos con el MLP\n",
    "    num_hidden_layers: list de enteros con el numero de capdas\n",
    "        ocultas a usar\n",
    "    num_neurons: list de enteros con el numero de neuronas a usar\n",
    "    X: matriz de numpy con caracteristicas\n",
    "    Y: vector numpy con las variables a predecir\n",
    "    \n",
    "    Retorna: dataframe con 6 columnas:\n",
    "        - numero de capas, numero de neuronas\n",
    "        - promedio de error prueba variable 1 y desviación estandar\n",
    "        - promedio de error prueba variable 2 y desviación estandar\n",
    "        \n",
    "    \"\"\"\n",
    "    #Validamos el modelo\n",
    "    Folds = 3\n",
    "    ss = ShuffleSplit(n_splits=Folds, test_size=0.2, random_state=1)\n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0\n",
    "    for hidden_layers in num_hidden_layers:\n",
    "        for neurons in num_neurons:\n",
    "            for j, (train, test) in enumerate(ss.split(X)):\n",
    "                # para almacenar errores intermedios\n",
    "                ErrorY1 = np.zeros(Folds)\n",
    "                ErrorY2 = np.zeros(Folds)\n",
    "                Xtrain= X[train,:]\n",
    "                Ytrain = Y[train,:]\n",
    "                Xtest = X[test,:]\n",
    "                Ytest = Y[test,:]\n",
    "                #Normalizamos los datos\n",
    "                scaler = StandardScaler().fit(X= Xtrain)       \n",
    "                Xtrain = scaler.transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "                # prestar atención a los parametros, correctos.\n",
    "                hidden_layer_sizes = tuple()\n",
    "                mlp = MLPRegressor(hidden_layer_sizes= hidden_layer_sizes, random_state=1...)\n",
    "                # entrena el MLP\n",
    "                mlp\n",
    "                # Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
    "                Yest = mlp\n",
    "                # Mida el MAPE para cada una de las dos salidas\n",
    "                # Observe bien la documentación. recordar que esta resolviendo\n",
    "                # un problema de multiples salidas\n",
    "                errors = (Ytest, Yest, ...)\n",
    "                ErrorY1[j] = ...\n",
    "                ErrorY2[j] =...\n",
    "        \n",
    "            print('error para salida 1 = ' + str(np.mean(ErrorY1)) + '+-' + str(np.std(ErrorY1)))\n",
    "            print('error para salida 2 = ' + str(np.mean(ErrorY2)) + '+-' + str(np.std(ErrorY2)))\n",
    "        \n",
    "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
    "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
    "            resultados.loc[idx,'error de prueba y1(media)'] = np.mean(ErrorY1)\n",
    "            resultados.loc[idx,'intervalo de confianza y1'] = np.std(ErrorY1)\n",
    "            resultados.loc[idx,'error de prueba y2(media)'] = np.mean(ErrorY2)\n",
    "            resultados.loc[idx,'intervalo de confianza y2'] = np.std(ErrorY2)\n",
    "            idx+=1\n",
    "    return (resultados)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TBVxxl25odt1"
   },
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "# ignorar los prints\n",
    "GRADER.run_test(\"ejercicio2\", experimetar_mlp)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXCQp7oJw9gd"
   },
   "source": [
    "vamos a realizar los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hV-ka-ukodt3"
   },
   "source": [
    "# tarda unos minutos!!\n",
    "resultados_mlpr = experimetar_mlp(num_hidden_layers = [1,2,3], num_neurons  = [8,12,16], X=x, Y=y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7insQmbOodt5"
   },
   "source": [
    "# ver los resultados.\n",
    "import seaborn as sns\n",
    "sns.relplot(data = resultados_mlpr,  x='neuronas en capas ocultas', y = 'error de prueba y1(media)', style= 'capas ocultas', kind = 'line')\n",
    "sns.relplot(data = resultados_mlpr,  x='neuronas en capas ocultas', y = 'error de prueba y2(media)', style= 'capas ocultas', kind = 'line')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "CpSvl_I4odt7"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown con base a los reusltados, ¿podriamos saber a priori los mejores parametros (capas ocultas, # de neuronas), que tan correcto es asumir patrones en los valores de los parametros?\n",
    "respuesta_2 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "4y1IDLzsw9ge"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown qué ocurre si cambiamos el valor de random state? los resultados deberían ser iguales? justifique su respuesta usando los conceptos teóricos.\n",
    "respuesta_3 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY2yg06Nodt8"
   },
   "source": [
    "### Ejercicio 2 Experimentar con MLP para clasificación\n",
    "\n",
    "A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasifiación de dígitos escritos a mano. Usaremos únicamente 4 de las 10 clases disponibles. Los datos fueron preprocesados para reducir el número de características. La técnica usada será analizada más adelante en el curso."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rQQrTIcZodt9"
   },
   "source": [
    "digits = load_digits(n_class=4)\n",
    "#--------- preprocesamiento--------------------\n",
    "pca = PCA(0.99, whiten=True)\n",
    "data = pca.fit_transform(digits.data)\n",
    "#---------- Datos a usar ----------------------\n",
    "Xd = data\n",
    "Yd = digits.target"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "AAZkhxDjodt_"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Qué tipo de función de activación usa el modelo en la capa de salida para un problema de clasificación?\n",
    "respuesta_4 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6VwPK9RoduA"
   },
   "source": [
    "como lo hicmos antes, vamos a comprobar con la libreria la función de activación"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "10TRJf1SoduB"
   },
   "source": [
    "# ejercicio de código\n",
    "def output_activation_MPC():\n",
    "    \"\"\"funcion que entrena un modelo\n",
    "    con data aleatoria para confirmar la funcion\n",
    "    de activacion de la ultima capa\n",
    "    \"\"\"\n",
    "    mlp = MLPClassifier()\n",
    "    # fit with some random data\n",
    "    xrandom = np.random.rand(10,2)\n",
    "    yrandom = np.zeros(10)\n",
    "    # llamar el metodo adecuado para entrenar\n",
    "    # el mlp con los x y 'y' random\n",
    "    mlp.fit(, )\n",
    "    # retornar el atributo de mlp adecuado\n",
    "    return (mlp)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l-JlGyNsoduC"
   },
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio3\", output_activation_MPC)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LR1AWh6doduE"
   },
   "source": [
    "print(\"la función de activación para un problema de clasificación es:\", output_activation_MPC())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUrb8sX1oduG"
   },
   "source": [
    "Ahora en nuestro siguiente ejercicio vamos a implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de clasificación. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPXRYrtnoduG"
   },
   "source": [
    "\n",
    "Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de clasificación propuesto.\n",
    "1. Como función de activación en las capas ocultas use la función tangencial hiperbólica. \n",
    "2. Ajuste el número máximo de épocas a 350.\n",
    "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa\n",
    "5. Seleccione la función adecuada del [modulo de sklearn para calcular la exactitud del clasificador](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta que parametros usar.\n",
    "6. Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro `activation`, debe ser llamado: `MLPClassifier(activation=...)`\n",
    "\n",
    "**NOTA**: cuando observe el el parametro `random_state=1` por favor conservarlo, ya que esto hace que los resultados sean similares a lo largo de las ejecucciones. *tener en cuenta esta observación para una de las preguntas abiertas que encuentras mas adelante del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pO3RLo4JoduG"
   },
   "source": [
    "# ejercicio de código\n",
    "def experimetar_mlpc(X,Y, num_hidden_layers, num_neurons):\n",
    "    \"\"\" función para realizar experimentos con el MLP\n",
    "    x: matriz de numpy con caracteristicas\n",
    "    y: vector numpy con las variables a predecir\n",
    "    num_hidden_layers: list de enteros con el numero de capdas\n",
    "        ocultas a usar\n",
    "    num_neurons: list de enteros con el numero de neuronas a usar\n",
    "    \n",
    "    Retorna: dataframe con 4 columnas:\n",
    "        - numero de capas, numero de neuronas\n",
    "        - promedio de error prueba (exactitud/eficiencia) de claisficacion y desviación estandar        \n",
    "    \"\"\"\n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    skf = StratifiedKFold(n_splits=Folds) \n",
    "    resultados = pd.DataFrame()\n",
    "    idx = 0\n",
    "    for hidden_layers in num_hidden_layers:\n",
    "        for neurons in num_neurons:\n",
    "            for j, (train, test) in enumerate(skf.split(X, Y)):\n",
    "                # para almacenar errores intermedios\n",
    "                Error = np.zeros(Folds)\n",
    "                Xtrain= X[train,:]\n",
    "                Ytrain = Y[train]\n",
    "                Xtest = X[test, :]\n",
    "                Ytest = Y[test]\n",
    "                #Normalizamos los datos\n",
    "                scaler = StandardScaler().fit(X= Xtrain)       \n",
    "                Xtrain = scaler.transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "                # prestar atención a los parametros, correctos.\n",
    "                hidden_layer_sizes = tuple(...)\n",
    "                #print(hidden_layer_sizes)\n",
    "                mlp = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, ... random_state = 1)\n",
    "                # entrenar el MLP\n",
    "                mlp...\n",
    "                #Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
    "                Yest = mlp.\n",
    "                # recordar usar la medida adecuada de acuerdo a las instrucciones\n",
    "                Error[j] = ...(Ytest, Yest)\n",
    "        \n",
    "            print('error para configuracion de params = ' + str(np.mean(Error)) + '+-' + str(np.std(Error)))\n",
    "        \n",
    "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
    "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
    "            resultados.loc[idx,'error de prueba(media)'] = np.mean(Error)\n",
    "            resultados.loc[idx,'intervalo de confianza'] = np.std(Error)\n",
    "            idx+=1\n",
    "    return (resultados)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kcMLaM4coduI"
   },
   "source": [
    "## la funcion que prueba tu implementacion\n",
    "GRADER.run_test(\"ejercicio4\", experimetar_mlpc)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iCyR-W0RoduJ"
   },
   "source": [
    "# tarda unos minutos!!\n",
    "resultados_mlpc = experimetar_mlpc(X = Xd, Y=Yd, num_hidden_layers=[1,2,3], num_neurons=[12,16,20])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_FwrY7LFoduL"
   },
   "source": [
    "# ver los resultados\n",
    "# notar como las capas ocultas y el # de neuronas influyen\n",
    "import seaborn as sns\n",
    "sns.relplot(data = resultados_mlpc,  x='neuronas en capas ocultas', y = 'exactitud en prueba(media)', style= 'capas ocultas', kind = 'line')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "IZJGmEnZoduO"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown ¿Cuántas neuronas en la capa de salida tiene el modelo? ¿Porqué debe tener ese número?\n",
    "respuesta_5 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "koqUM4gZw9gh"
   },
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown Llegas a una nueva compañía. Solo tienen perceptrones multicapa entrenados usado sklearn ¿que recomiendas?\n",
    "respuesta_6 = \"\" #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGfDfjGkoduP"
   },
   "source": [
    "**recordatorio** En la practica sklearn no es una la libreria indicada para desarollar redes neuronales, para practicas mas avanzadas y realizar modelos en el \"mundo real\" [se deben usar conceptos de deep learning y una libreria llamada Keras](https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb). Adicional tener en cuenta [lo visto en teoria](https://jdariasl.github.io/ML_2020/Clase%2012%20-%20Redes%20Neuronales%20Artificiales.html#desventajas-de-las-aproximaciones-clasicas)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1aRu5586oduP"
   },
   "source": [
    "GRADER.check_tests()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "wL-i0zZyoduR"
   },
   "source": [
    "#@title Integrantes\n",
    "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
    "codigo_integrante_2 = ''  #@param {type:\"string\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOcAojtRoduT"
   },
   "source": [
    "----\n",
    "esta linea de codigo va fallar, es de uso exclusivo del profesor\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6M_nkZ_DoduT"
   },
   "source": [
    "GRADER.grade()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Copyright**\n",
    "\n",
    "The notebooks are provided as [Open Educational Resource](https://de.wikipedia.org/wiki/Open_Educational_Resources). Feel free to use the notebooks for your own educational purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
